# Comprehensive Logging Guide

This document explains all the logs you'll see when running the UX Heuristic Analysis Tool in VS Code.

## Log Types & Emoji Guide

### Frontend Logs (Browser Console & VS Code Terminal)

| Emoji | Type | Description |
|-------|------|-------------|
| ğŸ¯ | Flow Control | Indicates a major step in the user flow |
| ğŸš€ | Initiation | Starting a process or function |
| âœ… | Success | Operation completed successfully |
| âŒ | Error | Operation failed or encountered an error |
| ğŸ“Š | Data/Config | Configuration settings or data being used |
| ğŸ“¡ | API Call | Making a request to backend/edge function |
| ğŸ“¥ | Response | Received response from backend |
| ğŸ’¾ | Database | Database operations (read/write) |
| ğŸ”„ | Refresh/Retry | Retrying or restarting an operation |
| ğŸ“ˆ | Progress | Progress updates during long operations |
| ğŸ” | Check/Query | Polling or checking status |
| â±ï¸ | Timing | Time-based operations |
| ğŸ›‘ | Cleanup | Cleaning up resources |

### Backend Logs (Edge Functions)

Backend logs use clear text with visual separators:

```
============================================================
PROFESSIONAL-GRADE MULTI-STAGE HEURISTIC EVALUATION
============================================================
```

## Complete Analysis Flow Example

### 1. Single Page Analysis

#### Frontend Logs:
```
ğŸ¯ [FRONTEND] Form submitted - Starting analysis flow
ğŸ“‹ [FRONTEND] Analysis type: single
ğŸŒ [FRONTEND] URL: https://example.com
âœ… [FRONTEND] URL validation passed
â¡ï¸ [FRONTEND] Executing single-page analysis
ğŸš€ [FRONTEND] Starting single-page analysis for: https://example.com
ğŸ“Š [FRONTEND] Using heuristics: {set: "nn_10", custom: []}
ğŸ“¡ [FRONTEND] Invoking analyze-website edge function...
ğŸ“¥ [FRONTEND] Received response from backend: {...}
âœ… [FRONTEND] Analysis data received: {
  score: 85,
  violations: 5,
  strengths: 8,
  screenshot: true
}
ğŸ’¾ [FRONTEND] Saving results to database for user: abc-123
ğŸ“ [FRONTEND] Inserting analysis result for project: xyz-456
âœ… [FRONTEND] Analysis saved to database
ğŸ”„ [FRONTEND] Navigating to results page
âœ… [FRONTEND] Analysis/Crawl initiated successfully
```

#### Backend Edge Function Logs:
```
============================================================
PROFESSIONAL-GRADE MULTI-STAGE HEURISTIC EVALUATION
============================================================
URL: https://example.com
Heuristics config: {set: "nn_10", custom: []}

[STEP 0] Scraping website with Firecrawl...
âœ“ Scraping complete

[STAGE 1] Deep Visual Decomposition...
âœ“ Stage 1 complete

[STAGE 2] Structural Analysis...
âœ“ Stage 2 complete

[STAGE 3] Per-Heuristic Evaluation (10 focused analyses)...
  Evaluating 10 heuristics...
âœ“ Stage 3 complete: 15 violations, 12 strengths

[STAGE 4] Cross-Validation & Deduplication...
âœ“ Stage 4 complete: 5 validated violations
  Removed: 8 duplicates, 2 false positives

[STAGE 5] Research-Backed Scoring...
âœ“ Stage 5 complete: Final score 85/100

============================================================
ANALYSIS COMPLETE
============================================================
Total violations: 5
Total strengths: 12
Final score: 85/100
Industry percentile: Top 35% - Above Average UX
============================================================
```

### 2. Full Website Crawl

#### Frontend Logs:
```
ğŸ¯ [FRONTEND] Form submitted - Starting analysis flow
ğŸ“‹ [FRONTEND] Analysis type: full
ğŸŒ [FRONTEND] URL: https://example.com
âœ… [FRONTEND] URL validation passed
â¡ï¸ [FRONTEND] Executing full website crawl
ğŸš€ [FRONTEND] Starting full website crawl for: https://example.com
ğŸ“Š [FRONTEND] Crawl mode: light
ğŸ” [FRONTEND] Finding or creating project...
âœ… [FRONTEND] Project ID: project-abc-123
ğŸ“¡ [FRONTEND] Invoking start-website-crawl edge function...
ğŸ“¥ [FRONTEND] Crawl response: {
  success: true,
  crawlId: "crawl-xyz-789"
}
âœ… [FRONTEND] Crawl started successfully with ID: crawl-xyz-789
âœ… [FRONTEND] Analysis/Crawl initiated successfully
ğŸ”„ [FRONTEND] Starting crawl status polling for ID: crawl-xyz-789
â±ï¸ [FRONTEND] Poll interval started (every 3 seconds)

ğŸ” [FRONTEND] Poll #1 - Checking crawl status...
ğŸ“¡ [FRONTEND] Invoking check-crawl-status...
ğŸ“Š [FRONTEND] Crawl status received: {
  status: "crawling",
  crawled: 5,
  analyzed: 0,
  total: 50
}

ğŸ” [FRONTEND] Poll #2 - Checking crawl status...
ğŸ“¡ [FRONTEND] Invoking check-crawl-status...
ğŸ“Š [FRONTEND] Crawl status received: {
  status: "crawling",
  crawled: 12,
  analyzed: 0,
  total: 50
}
ğŸ“ˆ [FRONTEND] Progress updated: 5 -> 12

... (polling continues every 3 seconds) ...

ğŸ” [FRONTEND] Poll #45 - Checking crawl status...
ğŸ“¡ [FRONTEND] Invoking check-crawl-status...
ğŸ“Š [FRONTEND] Crawl status received: {
  status: "analyzing",
  crawled: 50,
  analyzed: 25,
  total: 50
}
ğŸ“ˆ [FRONTEND] Progress updated: 50 -> 75

... (polling continues) ...

ğŸ” [FRONTEND] Poll #60 - Checking crawl status...
ğŸ“¡ [FRONTEND] Invoking check-crawl-status...
ğŸ“Š [FRONTEND] Crawl status received: {
  status: "completed",
  crawled: 50,
  analyzed: 50,
  total: 50
}
âœ… [FRONTEND] Crawl completed successfully!
ğŸ›‘ [FRONTEND] Cleaning up poll interval
```

#### Backend Edge Function Logs (start-website-crawl):
```
Starting full website crawl for: https://example.com with mode: light
User: user-123 Project: project-456
Initiating Firecrawl crawl with light mode: 50 pages max, depth 2
Firecrawl job started: firecrawl-job-abc
Crawl job created: crawl-xyz-789
```

#### Backend Edge Function Logs (check-crawl-status):
```
Checking crawl status for: crawl-xyz-789
Firecrawl status: scraping
Firecrawl initial response - Status: scraping Completed: 5 Total: 50

... (logs continue with each status check) ...

Checking crawl status for: crawl-xyz-789
Firecrawl status: completed
âœ… All data fetched! Total pages: 50
âœ… Crawl ready for analysis! Total pages crawled: 50
[Starting analysis of 50 pages...]
```

## Error Scenarios

### 1. Invalid URL
```
ğŸ¯ [FRONTEND] Form submitted - Starting analysis flow
ğŸ“‹ [FRONTEND] Analysis type: single
ğŸŒ [FRONTEND] URL: not-a-url
âŒ [FRONTEND] Invalid URL format
```

### 2. API Key Missing
```
ğŸš€ [FRONTEND] Starting single-page analysis for: https://example.com
ğŸ“¡ [FRONTEND] Invoking analyze-website edge function...
âŒ [FRONTEND] Backend error: {message: "FIRECRAWL_API_KEY not configured"}
âŒ [FRONTEND] Analysis error: Error: FIRECRAWL_API_KEY not configured
```

### 3. Rate Limit Exceeded
```
ğŸš€ [FRONTEND] Starting full website crawl for: https://example.com
ğŸ“¡ [FRONTEND] Invoking start-website-crawl edge function...
âŒ [FRONTEND] Crawl error: Error: rate limit
âŒ [FRONTEND] Rate limit error detected
```

### 4. Crawl Timeout
```
ğŸ” [FRONTEND] Poll #401 - Checking crawl status...
âŒ [FRONTEND] Polling timeout after 1203 seconds
```

### 5. Crawl Stuck (Auto-Restart)
```
ğŸ”„ [FRONTEND] Backend signaled restart needed due to error
ğŸ”„ [FRONTEND] Executing auto-restart...
ğŸ”„ [FRONTEND] Marking old crawl as error...
â±ï¸ [FRONTEND] Waiting 2 seconds before restart...
ğŸš€ [FRONTEND] Restarting crawl...
âœ… [FRONTEND] Auto-restart successful
```

## Debugging Tips

### Finding Specific Logs

#### In Browser DevTools:
1. Open DevTools (F12)
2. Go to Console tab
3. Use filter:
   - Type `[FRONTEND]` to see only frontend logs
   - Type `âŒ` to see only errors
   - Type `âœ…` to see only successes
   - Type a specific function like `analyze-website` to filter

#### In VS Code Terminal:
- Frontend dev server logs appear where you ran `npm run dev`
- Look for the colored emoji prefixes
- Scroll up to see earlier logs

#### In Supabase Logs:
```bash
# All edge function logs
supabase functions logs

# Specific function
supabase functions logs analyze-website

# Follow logs in real-time
supabase functions logs --tail

# Search for specific text
supabase functions logs | grep "error"
```

### Common Issues & Their Logs

#### Issue: Analysis Takes Forever

**Look for:**
```
ğŸ” [FRONTEND] Poll #X - Checking crawl status...
```

If X keeps increasing with no progress updates (`ğŸ“ˆ`), the crawl is stuck.

**Check backend logs:**
```bash
supabase functions logs check-crawl-status --tail
```

Look for: `Firecrawl appears stuck`

#### Issue: No Results After Analysis

**Check for:**
```
âœ… [FRONTEND] Analysis data received: {score: undefined, violations: 0, ...}
```

This means the backend returned empty data.

**Check backend logs:**
```bash
supabase functions logs analyze-website
```

Look for errors in STAGE 3, 4, or 5.

#### Issue: Database Save Failed

**Look for:**
```
ğŸ’¾ [FRONTEND] Saving results to database for user: ...
âŒ [FRONTEND] Error: ...
```

Usually means RLS policy issue or network problem.

#### Issue: Edge Function Not Found

**Look for:**
```
ğŸ“¡ [FRONTEND] Invoking analyze-website edge function...
âŒ [FRONTEND] Backend error: {message: "Function not found"}
```

**Solution:**
```bash
supabase functions deploy analyze-website
```

## Performance Monitoring

### Single Page Analysis
- **Expected time**: 20-30 seconds
- **Key stages**:
  - Scraping: 3-5 seconds
  - Visual decomposition: 8-12 seconds
  - Heuristic evaluation: 10-15 seconds

**Look for:**
```
[STEP 0] Scraping... âœ“ (5s)
[STAGE 1] Visual... âœ“ (10s)
[STAGE 2] Structural... âœ“ (1s)
[STAGE 3] Heuristics... âœ“ (12s)
[STAGE 4] Validation... âœ“ (1s)
[STAGE 5] Scoring... âœ“ (1s)
```

### Full Website Crawl
- **Expected time**: 1-10 minutes (depends on page count)
- **Progress updates**: Every 3 seconds

**Monitor:**
```
ğŸ“ˆ [FRONTEND] Progress updated: 0 -> 10
ğŸ“ˆ [FRONTEND] Progress updated: 10 -> 25
ğŸ“ˆ [FRONTEND] Progress updated: 25 -> 40
```

If no progress for > 30 seconds, something's wrong.

## Advanced Debugging

### Enable Verbose Logging

Add to your `.env`:
```
VITE_DEBUG=true
```

### Network Tab Analysis

In Browser DevTools > Network:
1. Filter by "Fetch/XHR"
2. Look for requests to:
   - `functions/v1/analyze-website`
   - `functions/v1/start-website-crawl`
   - `functions/v1/check-crawl-status`
3. Check:
   - Request payload
   - Response status
   - Response body
   - Time taken

### Database Queries

Monitor real-time database activity:
```sql
-- Check crawl status directly
SELECT id, status, crawled_pages, analyzed_pages, total_pages, error_message
FROM website_crawls
WHERE id = 'your-crawl-id'
ORDER BY created_at DESC;

-- Check analysis results
SELECT id, score, created_at
FROM analysis_results
WHERE project_id = 'your-project-id'
ORDER BY created_at DESC;
```

## Log Retention

- **Browser console**: Cleared on page refresh
- **VS Code terminal**: Visible until you close terminal
- **Supabase logs**: Retained for 7 days (free tier)

## Quick Reference

### Most Important Logs to Watch

**For Single Page:**
```
ğŸš€ Starting analysis
ğŸ“Š Analysis data received
âœ… Analysis saved
```

**For Crawl:**
```
âœ… Crawl started successfully
ğŸ” Poll #X - Checking status
ğŸ“ˆ Progress updated
âœ… Crawl completed
```

**For Errors:**
```
âŒ [FRONTEND] Any error message
```

### Log Locations Summary

| What | Where |
|------|-------|
| Frontend UI events | Browser Console (F12) |
| Frontend network | Browser Network Tab |
| Frontend dev server | VS Code Terminal (npm run dev) |
| Backend edge functions | `supabase functions logs` |
| Database queries | Supabase Dashboard or CLI |

---

**Remember**: Logs are your best friend for debugging. Always check them first!
